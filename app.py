import streamlit as st
import pandas as pd
import numpy as np
import io
import os
import requests
import time
from pandasai.llm.base import LLM
from pandasai import SmartDatalake

# -------------------------------------------------------------------
# æ¨¡å—ä¸€: è‡ªå®šä¹‰çš„ AI æ¨¡å‹æ¥å£ (ä¿æŒä¸å˜)
# -------------------------------------------------------------------
class DeepSeekLLM(LLM):
    """ä¼˜åŒ–çš„DeepSeek LLMé›†æˆç±»"""
    def __init__(self, api_key: str, model: str = "deepseek-chat", temperature: float = 0.1):
        super().__init__()
        self.api_key = api_key; self.model = model; self.temperature = temperature; self.api_base = "https://api.deepseek.com/v1"
    def call(self, prompt: str, *args, **kwargs) -> str:
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        payload = {"model": self.model, "messages": [{"role": "user", "content": str(prompt)}], "temperature": self.temperature, "max_tokens": 4096}
        try:
            response = requests.post(f"{self.api_base}/chat/completions", headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
        except Exception as e:
            return f"APIè¯·æ±‚æˆ–ç½‘ç»œå‘ç”Ÿé”™è¯¯: {e}"
    @property
    def type(self) -> str: return "deepseek-llm"

# -------------------------------------------------------------------
# æ¨¡å—äºŒ: æœ€ç»ˆç‰ˆçš„æ•°æ®å›å¡«å‡½æ•°ï¼ˆå¢åŠ ä¸“å®¶çº§æ¸…æ´—å’Œè°ƒè¯•ï¼‰
# -------------------------------------------------------------------
def fill_template_final(template_df: pd.DataFrame, source_dfs: list, key_columns: list, columns_to_fill: list, 
                      template_path: str = None, inplace: bool = False) -> pd.DataFrame:
    """
    æ ¹æ®å¤šä¸ªå…³é”®åˆ—åŒ¹é…ï¼Œå¯¹æŒ‡å®šåˆ—è¿›è¡Œæ±‚å’Œå¹¶å›å¡«ã€‚
    å‚æ•°:
        template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæä¾›ä¸”inplace=Trueåˆ™ç›´æ¥ä¿®æ”¹è¯¥æ–‡ä»¶
        inplace: æ˜¯å¦ç›´æ¥ä¿®æ”¹æ¨¡æ¿æ–‡ä»¶
    """
    
    # ä¸“å®¶çº§æ•°æ®æ¸…æ´—å‡½æ•°
    def expert_clean_df(df):
        df_clean = df.copy()
        for col in df_clean.columns:
            # åªå¯¹å­—ç¬¦ä¸²ç±»å‹æ‰§è¡Œå­—ç¬¦ä¸²æ“ä½œ
            if pd.api.types.is_string_dtype(df_clean[col]):
                df_clean[col] = df_clean[col].astype(str).str.strip()
            # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
            try:
                df_clean[col] = pd.to_numeric(df_clean[col], errors='ignore')
            except:
                pass
        return df_clean

    cleaned_template_df = expert_clean_df(template_df)
    cleaned_source_dfs = [expert_clean_df(df) for df in source_dfs]

    # æ”¹è¿›å…³é”®åˆ—å¤„ç† - ä¿ç•™åŸå§‹æ ¼å¼ç”¨äºåŒ¹é…
    for df in [cleaned_template_df] + cleaned_source_dfs:
        for key in key_columns:
            if key in df.columns:
                # ä¿ç•™åŸå§‹å€¼ç”¨äºè°ƒè¯•
                df['_original_'+key] = df[key]  
                # æ ‡å‡†åŒ–å¤„ç†
                df[key] = df[key].fillna('N/A').astype(str).str.strip().str.lower().str.replace(r'\s+', '', regex=True)

    valid_sources = [df for df in cleaned_source_dfs if all(key in df.columns for key in key_columns)]
    if not valid_sources: raise ValueError("æ•°æ®æºæ–‡ä»¶ä¸­ç¼ºå°‘éƒ¨åˆ†æˆ–å…¨éƒ¨å…³é”®åˆ—ã€‚")
    
    combined_sources = pd.concat(valid_sources, ignore_index=True)
    
    # æ”¹è¿›èšåˆé€»è¾‘ - ä¿ç•™æ–‡æœ¬åˆ—
    agg_functions = {}
    for col in columns_to_fill:
        if col in combined_sources.columns:
            if pd.api.types.is_numeric_dtype(combined_sources[col]):
                agg_functions[col] = 'sum'
            else:
                agg_functions[col] = 'first'  # ä¿ç•™ç¬¬ä¸€ä¸ªéç©ºå€¼
    
    if not agg_functions: return cleaned_template_df
    
    # è¯†åˆ«å¹¶ä¿ç•™ç‰¹æ®Šè¡Œï¼ˆå¦‚"é¡¹ç›®"ã€"ä¸€"ç­‰ï¼‰
    special_rows = combined_sources[
        combined_sources[key_columns[0]].astype(str).str.contains('é¡¹ç›®|ä¸€|â€”', regex=True)
    ]
    
    # æ‰§è¡Œå¸¸è§„èšåˆ
    aggregated_source = combined_sources.groupby(key_columns, as_index=False).agg(agg_functions)
    
    # åˆå¹¶ç‰¹æ®Šè¡Œå’Œèšåˆç»“æœ
    aggregated_source = pd.concat([special_rows, aggregated_source]).drop_duplicates(subset=key_columns, keep='first')
    
    # --- è°ƒè¯•ä¿¡æ¯å°†ç›´æ¥æ˜¾ç¤º ---
    st.markdown("---")
    st.subheader("âš™ï¸ è°ƒè¯•è¯Šæ–­ä¿¡æ¯ (è¯·ä»”ç»†æ¯”å¯¹ä»¥ä¸‹ä¸¤ä¸ªè¡¨æ ¼)")
    st.write("**1. æ¨¡æ¿æ–‡ä»¶å…³é”®åˆ— (æ¸…æ´—åç”¨äºåŒ¹é…çš„å€¼):**")
    st.dataframe(cleaned_template_df[key_columns].head())
    st.write("**2. æºæ•°æ®å…³é”®åˆ— (æ¸…æ´—å¹¶èšåˆåç”¨äºåŒ¹é…çš„å€¼):**")
    st.dataframe(aggregated_source[key_columns].head())
    st.markdown("---")
    
    for key in key_columns:
        cleaned_template_df[key] = cleaned_template_df[key].astype(str)
        
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    st.write("**åˆå¹¶å‰æ¨¡æ¿æ•°æ®æ ·æœ¬:**")
    st.dataframe(cleaned_template_df.head())
    st.write("**åˆå¹¶å‰åˆ†æç»“æœæ ·æœ¬:**")
    st.dataframe(aggregated_source.head())
    
    # æ”¹è¿›åˆå¹¶é€»è¾‘ - å¤„ç†éå”¯ä¸€é”®
    # å…ˆä¸ºæ¨¡æ¿æ•°æ®æ·»åŠ ä¸´æ—¶ç´¢å¼•åˆ—
    cleaned_template_df['_temp_index'] = range(len(cleaned_template_df))
    
    # æ‰§è¡Œåˆå¹¶ï¼Œä¸éªŒè¯ä¸€å¯¹ä¸€å…³ç³»
    # æ”¹è¿›åˆå¹¶é€»è¾‘ - æ·»åŠ è°ƒè¯•ä¿¡æ¯
    st.write("**å…³é”®åˆ—åŒ¹é…è¯¦æƒ…:**")
    st.write(f"æ¨¡æ¿æ•°æ®å…³é”®åˆ—å€¼: {cleaned_template_df[key_columns].head().to_dict()}")
    st.write(f"æºæ•°æ®å…³é”®åˆ—å€¼: {aggregated_source[key_columns].head().to_dict()}")
    
    # æ‰§è¡Œåˆå¹¶å¹¶æ˜¾ç¤ºæœªåŒ¹é…è®°å½•
    merged_df = pd.merge(
        cleaned_template_df,
        aggregated_source,
        on=key_columns,
        how='left',
        suffixes=('', '_source'),
        indicator=True  # æ·»åŠ åˆå¹¶æ ‡è®°
    )
    
    # æ˜¾ç¤ºæœªåŒ¹é…çš„è®°å½•
    unmatched = merged_df[merged_df['_merge'] == 'left_only']
    if not unmatched.empty:
        st.warning(f"å‘ç° {len(unmatched)} æ¡æœªåŒ¹é…è®°å½•")
        st.dataframe(unmatched[key_columns + ['_merge']])
    
    merged_df = merged_df.drop(columns=['_merge'])  # ç§»é™¤åˆå¹¶æ ‡è®°
    
    # æŒ‰åŸå§‹é¡ºåºæ¢å¤å¹¶åˆ é™¤ä¸´æ—¶ç´¢å¼•
    merged_df = merged_df.sort_values('_temp_index').drop(columns=['_temp_index'])
    
    # æ£€æŸ¥åˆå¹¶ç»“æœ
    st.write("**åˆå¹¶åæ•°æ®æ ·æœ¬:**")
    st.dataframe(merged_df.head())

    for col in columns_to_fill:
        source_col_name = f"{col}_source"
        if source_col_name in merged_df.columns:
            # æ”¹è¿›çš„ç©ºç™½æ›¿æ¢é€»è¾‘ - æ”¾å®½æ¡ä»¶
            # åªè¦æºæ•°æ®æœ‰å€¼ä¸”æ¨¡æ¿å€¼ä¸ºç©º/0/None/ç©ºå­—ç¬¦ä¸²ï¼Œå°±è¿›è¡Œæ›¿æ¢
            if pd.api.types.is_numeric_dtype(merged_df[col].dtype):
                mask_to_fill = (merged_df[col].isna()) | (merged_df[col] == 0) | (merged_df[col].astype(str) == "None") | (merged_df[col].astype(str) == "nan")
            else:
                mask_to_fill = (merged_df[col].isna()) | (merged_df[col] == "") | (merged_df[col].astype(str) == "None") | (merged_df[col].astype(str) == "nan")
            
            # ç¡®ä¿æºæ•°æ®æœ‰å€¼æ—¶æ‰æ›¿æ¢
            mask_to_fill = mask_to_fill & (~merged_df[source_col_name].isna())
            
            # æ‰§è¡Œæ›¿æ¢
            merged_df[col] = np.where(
                mask_to_fill,
                merged_df[source_col_name],
                merged_df[col]
            )
            merged_df.drop(columns=[source_col_name], inplace=True)

    final_df = merged_df[template_df.columns]
    for col in final_df.select_dtypes(include=np.number).columns:
        final_df[col] = final_df[col].fillna(0)
    
    # å¦‚æœæŒ‡å®šäº†æ¨¡æ¿è·¯å¾„ä¸”éœ€è¦ç›´æ¥ä¿®æ”¹
    if template_path and inplace:
        try:
            # è·å–åŸå§‹æ–‡ä»¶è·¯å¾„
            original_path = os.path.abspath(template_path)
            # åˆ›å»ºä¸´æ—¶å‰¯æœ¬(ä½¿ç”¨.xlsxæ‰©å±•å)
            temp_path = os.path.splitext(original_path)[0] + "_temp.xlsx"
            
            # å†™å…¥ä¿®æ”¹åçš„æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
            with pd.ExcelWriter(temp_path, engine='openpyxl') as writer:
                final_df.to_excel(writer, index=False)
            
            # æ›¿æ¢åŸå§‹æ–‡ä»¶
            if os.path.exists(original_path):
                os.remove(original_path)
            os.rename(temp_path, original_path)
            
            st.success(f"å·²æˆåŠŸä¿®æ”¹æœ¬åœ°æ–‡ä»¶: {original_path}")
        except Exception as e:
            st.error(f"ç›´æ¥ä¿®æ”¹æ–‡ä»¶å¤±è´¥: {e}")
            if os.path.exists(temp_path):
                os.remove(temp_path)
        
    return final_df

# -------------------------------------------------------------------
# ä¸»ç¨‹åº: Streamlit ç•Œé¢é€»è¾‘ (ç®€åŒ–ç‰ˆ)
# -------------------------------------------------------------------
def main():
    st.set_page_config(page_title="æ™ºèƒ½æ•°æ®åˆ†æå¹³å°", page_icon="ğŸ§ ", layout="wide")
    st.title("ğŸ§  æ™ºèƒ½æ•°æ®åˆ†æå¹³å°")

    with st.sidebar:
        st.header("ğŸ”‘ API å¯†é’¥")
        api_key = st.text_input("DeepSeek APIå¯†é’¥", type="password", help="ä»DeepSeekå®˜ç½‘è·å–APIå¯†é’¥")

    st.header("AI æ™ºèƒ½åˆ†æ")
    st.info("ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶ç”¨è‡ªç„¶è¯­è¨€æé—®ï¼ŒAIä¼šè‡ªåŠ¨åˆ†æå¹¶å¯å°†ç»“æœå¡«å…¥æŒ‡å®šæ¨¡æ¿ã€‚")
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    col1, col2 = st.columns(2)
    with col1:
        data_files = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶", type=["xlsx", "xls"], accept_multiple_files=True)
    with col2:
        template_option = st.radio("æ¨¡æ¿æ–‡ä»¶æ¥æº", 
                                 ["ä¸Šä¼ æ¨¡æ¿æ–‡ä»¶", "æŒ‡å®šæœ¬åœ°æ–‡ä»¶è·¯å¾„"],
                                 help="é€‰æ‹©ç›´æ¥ä¿®æ”¹æœ¬åœ°æ–‡ä»¶æˆ–ä¸Šä¼ æ¨¡æ¿æ–‡ä»¶")
        
        if template_option == "ä¸Šä¼ æ¨¡æ¿æ–‡ä»¶":
            template_file = st.file_uploader("ä¸Šä¼ æ¨¡æ¿æ–‡ä»¶", type=["xlsx", "xls"])
            local_path = None
        else:
            local_path = st.text_input("æœ¬åœ°æ¨¡æ¿æ–‡ä»¶è·¯å¾„", 
                                     placeholder="ä¾‹å¦‚: e:/ç”µå·¥æ¯/templates/report_template.xlsx")
            template_file = None

    # åˆ†æè¯·æ±‚è¾“å…¥
    prompt = st.text_area("åˆ†æéœ€æ±‚", height=100, 
                        placeholder="ä¾‹å¦‚: è®¡ç®—å„äº§å“çš„é”€å”®æ€»é¢å¹¶å¡«å…¥æ¨¡æ¿")

    if st.button("å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
        if not api_key or not api_key.startswith("sk-"):
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥ã€‚")
        elif not data_files:
            st.warning("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ•°æ®æ–‡ä»¶ã€‚")
        elif not prompt.strip():
            st.warning("è¯·è¾“å…¥æ‚¨çš„åˆ†æéœ€æ±‚ã€‚")
        else:
            with st.spinner("AI æ­£åœ¨åˆ†æä¸­..."):
                try:
                    # è¯»å–æ•°æ®æ–‡ä»¶
                    dfs = [pd.read_excel(f) for f in data_files]
                    
                    # åˆå§‹åŒ–AIæ¨¡å‹
                    llm = DeepSeekLLM(api_key=api_key)
                    lake = SmartDatalake(dfs, config={"llm": llm})
                    
                    # æ‰§è¡Œåˆ†æ
                    result = lake.chat(prompt)
                    
                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    st.subheader("åˆ†æç»“æœ")
                    if isinstance(result, pd.DataFrame):
                        st.dataframe(result)
                        
                        # å¤„ç†æ¨¡æ¿æ–‡ä»¶
                        if template_option == "ä¸Šä¼ æ¨¡æ¿æ–‡ä»¶" and template_file:
                            template_df = pd.read_excel(template_file)
                            # ä½¿ç”¨fill_template_finalå‡½æ•°å¤„ç†
                            result_df = fill_template_final(
                                template_df, [result], 
                                key_columns=template_df.columns.tolist()[:1],  # ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºå…³é”®åˆ—
                                columns_to_fill=result.columns.tolist()
                            )
                            
                            # æä¾›ä¸‹è½½
                            output = io.BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                result_df.to_excel(writer, index=False)
                            st.download_button(
                                "ä¸‹è½½å¡«å…¥æ¨¡æ¿çš„ç»“æœ", 
                                output.getvalue(), 
                                "analysis_result_in_template.xlsx"
                            )
                        
                        # å¤„ç†æœ¬åœ°æ–‡ä»¶è·¯å¾„
                        elif template_option == "æŒ‡å®šæœ¬åœ°æ–‡ä»¶è·¯å¾„" and local_path:
                            if os.path.exists(local_path):
                                template_df = pd.read_excel(local_path)
                                # ç›´æ¥ä¿®æ”¹æœ¬åœ°æ–‡ä»¶
                                result_df = fill_template_final(
                                    template_df, [result],
                                    key_columns=template_df.columns.tolist()[:1],
                                    columns_to_fill=result.columns.tolist(),
                                    template_path=local_path,
                                    inplace=True
                                )
                            else:
                                st.error("æŒ‡å®šçš„æœ¬åœ°æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
                    else:
                        st.write(result)
                        
                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()